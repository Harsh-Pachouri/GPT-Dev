{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/harshpachouri/gpt-dev?scriptVersionId=221975518\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","execution_count":1,"id":"8619db60","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2025-02-11T12:51:08.944177Z","iopub.status.busy":"2025-02-11T12:51:08.94394Z","iopub.status.idle":"2025-02-11T12:51:12.928513Z","shell.execute_reply":"2025-02-11T12:51:12.927584Z"},"papermill":{"duration":3.990473,"end_time":"2025-02-11T12:51:12.930438","exception":false,"start_time":"2025-02-11T12:51:08.939965","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/llm-data-set-of-julius-caesar/input.txt\n"]}],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","from dataclasses import dataclass\n","import math\n","import torch\n","import torch.nn as nn\n","import tiktoken\n","from torch.nn import functional as F\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":2,"id":"694c33d9","metadata":{"execution":{"iopub.execute_input":"2025-02-11T12:51:12.939711Z","iopub.status.busy":"2025-02-11T12:51:12.939223Z","iopub.status.idle":"2025-02-11T12:51:12.950978Z","shell.execute_reply":"2025-02-11T12:51:12.950114Z"},"papermill":{"duration":0.017274,"end_time":"2025-02-11T12:51:12.952648","exception":false,"start_time":"2025-02-11T12:51:12.935374","status":"completed"},"tags":[]},"outputs":[],"source":["class CausalSelfAttention(nn.Module):\n","\n","  def __init__(self,config):\n","    super().__init__()\n","    assert config.n_embd % config.n_head==0\n","\n","    self.c_attn = nn.Linear(config.n_embd, 3*config.n_embd)\n","    self.c_proj = nn.Linear(config.n_embd, config.n_embd)\n","    self.c_proj.NANOGPT_SCALE_INIT=1\n","    self.n_head = config.n_head\n","    self.n_embd = config.n_embd\n","\n","    self.register_buffer(\"bias\", torch.tril(torch.ones(config.block_size, config.block_size)).view(1,1,config.block_size, config.block_size))\n","\n","  def forward(self, x):\n","    B, T, C = x.size()\n","    qkv = self.c_attn(x)\n","    q, k, v = qkv.split(self.n_embd, dim=2)\n","    k = k.view(B,T,self.n_head, C // self.n_head).transpose(1,2)\n","    q = q.view(B,T,self.n_head, C // self.n_head).transpose(1,2)\n","    v = v.view(B,T,self.n_head, C // self.n_head).transpose(1,2)\n","\n","#    att = (q @ k.transpose(-2,-1)) * (1.0/math.sqrt(k.size(-1)))\n","#    att = att.masked_fill(self.bias[:,:,:T,:T].to(x.device)==0, -1e9)\n","#    att = F.softmax(att,dim=-1)\n","#    y=att @ v\n","    y = F.scaled_dot_product_attention(q,k,v,is_causal=True)\n","    y = y.transpose(1,2).contiguous().view(B,T,C)\n","    y = self.c_proj(y)\n","    return y\n","\n","class MLP(nn.Module):\n","\n","  def __init__(self,config):\n","    super().__init__()\n","    self.c_fc =   nn.Linear(config.n_embd,4 * config.n_embd)\n","    self.gelu =   nn.GELU(approximate='tanh')\n","    self.c_proj = nn.Linear(4*config.n_embd, config.n_embd)\n","    self.c_proj.NANOGPT_SCALE_INIT=1\n","  def forward(self,x):\n","    x = self.c_fc(x)\n","    x = self.gelu(x)\n","    x = self.c_proj(x)\n","    return x\n","\n","class Block(nn.Module):\n","\n","  def __init__(self,config):\n","    super().__init__()\n","    self.ln_1 = nn.LayerNorm(config.n_embd)\n","    self.attn = CausalSelfAttention(config)\n","    self.ln_2 = nn.LayerNorm(config.n_embd)\n","    self.mlp = MLP(config)\n","\n","  def forward(self,x):\n","    x = x + self.attn(self.ln_1(x))\n","    x = x+ self.mlp(self.ln_2(x))\n","    return x"]},{"cell_type":"code","execution_count":3,"id":"e19dd28e","metadata":{"execution":{"iopub.execute_input":"2025-02-11T12:51:12.960499Z","iopub.status.busy":"2025-02-11T12:51:12.960294Z","iopub.status.idle":"2025-02-11T12:51:12.977239Z","shell.execute_reply":"2025-02-11T12:51:12.976467Z"},"papermill":{"duration":0.021523,"end_time":"2025-02-11T12:51:12.978724","exception":false,"start_time":"2025-02-11T12:51:12.957201","status":"completed"},"tags":[]},"outputs":[],"source":["@dataclass\n","class GPTConfig:\n","  block_size: int = 1024\n","  vocab_size: int = 50257\n","  n_layer: int = 12\n","  n_head: int = 12\n","  n_embd: int = 768\n","\n","class GPT(nn.Module):\n","\n","  def __init__(self,config):\n","    super().__init__()\n","    self.config = config\n","\n","    self.transformer = nn.ModuleDict(dict(\n","        wte = nn.Embedding(config.vocab_size, config.n_embd),\n","        wpe = nn.Embedding(config.block_size, config.n_embd),\n","        h = nn.ModuleList([Block(config) for _ in range(config.n_layer)]),\n","        ln_f = nn.LayerNorm(config.n_embd),\n","    ))\n","    self.lm_head = nn.Linear(config.n_embd,config.vocab_size,bias=False)\n","    self.transformer.wte.weight = self.lm_head.weight\n","    self.apply(self._init_weight)\n","\n","  def _init_weight(self, module):\n","    if isinstance(module, nn.Linear):\n","      std=0.02\n","      if hasattr(module, 'NONOGPT_SCALE_INIT'):\n","        std*= (2*self.config.n_layer)**-0.5\n","      torch.nn.init.normal_(module.weight,mean=0.0,std = std)\n","      if module.bias is not None:\n","        torch.nn.init.zeros_(module.bias)\n","    elif isinstance(module, nn.Embedding):\n","      torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n","\n","\n","\n","\n","  def forward(self,idx, targets = None):\n","\n","    B,T = idx.size()\n","\n","    assert T<= self.config.block_size, f\"Cannot forward sequence of length{T}, block size is only {self.config.block_size}\"\n","    pos = torch.arange(0, T, dtype=torch.long, device = idx.device)\n","    pos_emb = self.transformer.wpe(pos).to(device=idx.device)\n","    tok_emb = self.transformer.wte(idx).to(device=idx.device)\n","    x = tok_emb + pos_emb\n","\n","    for block in self.transformer.h:\n","      x = block(x)\n","\n","    x = self.transformer.ln_f(x)\n","    logits = self.lm_head(x)\n","    loss=None\n","    if targets is not None:\n","      loss = F.cross_entropy(logits.view(-1,logits.size(-1)), targets.view(-1))\n","    return logits, loss\n","\n","  @classmethod\n","  def from_pretrained(cls,model_type):\n","    assert model_type in {'gpt2', 'gpt2-medium', 'gpt2-large', 'gpt2-xl'}\n","    from transformers import GPT2LMHeadModel\n","    print(\"loading weights from pretrained gpt : %s\" %model_type)\n","\n","    config_args = {\n","        'gpt2':         dict(n_layer=12, n_head=12, n_embd=768),\n","        'gpt2-medium':  dict(n_layer=24, n_head=16, n_embd=1024),\n","        'gpt2-large':   dict(n_layer=36, n_head=20, n_embd=1280),\n","        'gpt2-xl':      dict(n_layer=48, n_head=25, n_embd=1600),\n","    }[model_type]\n","\n","    config_args['vocab_size'] = 50257\n","    config_args['block_size'] = 1024\n","\n","    config = GPTConfig(**config_args)\n","    model = GPT(config)\n","    sd = model.state_dict()\n","    sd_keys=sd.keys()\n","    sd_keys = [k for k in sd_keys if not k.endswith('.attn.bias')]\n","\n","    model_hf = GPT2LMHeadModel.from_pretrained(model_type)\n","    sd_hf = model_hf.state_dict()\n","\n","    sd_keys_hf = sd_hf.keys()\n","    sd_keys_hf = [k for k in sd_keys_hf if not k.endswith('.attn.masked_bias')]\n","    sd_keys_hf = [k for k in sd_keys_hf if not k.endswith('.attn.bias')]\n","    transposed = ['attn.c_attn.weight', 'attn.c_proj.weight','mlp.c_fc.weight','mlp.c_proj.weight']\n","\n","    assert len(sd_keys_hf) == len(sd_keys), f\"mismatched keys: {len(sd_keys_hf)}!= {len(sd_keys)} \"\n","    for k in sd_keys_hf:\n","      if any(k.endswith(w) for w in transposed):\n","        assert sd_hf[k].shape[::-1]==sd[k].shape\n","        with torch.no_grad():\n","          sd[k].copy_(sd_hf[k].t())\n","      else:\n","        assert sd_hf[k].shape==sd[k].shape\n","        with torch.no_grad():\n","          sd[k].copy_(sd_hf[k])\n","\n","    return model\n","\n","from tiktoken import get_encoding  # Ensure tiktoken is installed\n","\n","import torch\n","import torch.nn.functional as F\n","from tiktoken import get_encoding  # Ensure tiktoken is installed\n","\n","def generate_text(model, input_text, max_tokens=50, device='cpu'):\n","  model.eval()  # Set model to evaluation mode\n","  tokenizer = get_encoding(\"gpt2\")  # Use GPT-2 tokenizer from tiktoken\n","\n","  # Allow <|endoftext|> as a special token\n","  eos_token_id = tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}).pop()\n","  input_ids = tokenizer.encode(input_text, allowed_special={\"<|endoftext|>\"})  # Tokenize the input text\n","  input_tensor = torch.tensor(input_ids, dtype=torch.long).unsqueeze(0).to(device)  # Add batch dimension\n","\n","  # Generate tokens\n","  generated_ids = input_tensor\n","  for _ in range(max_tokens):\n","    with torch.no_grad():\n","      logits, _ = model(generated_ids)  # Forward pass\n","      logits = logits[:, -1, :]  # Logits for the last token\n","      probs = F.softmax(logits, dim=-1)  # Convert logits to probabilities\n","      next_token = torch.multinomial(probs, num_samples=1)  # Sample next token\n","      generated_ids = torch.cat((generated_ids, next_token), dim=1)  # Append new token\n","\n","      # Stop if the end-of-text token is generated\n","      if next_token.item() == eos_token_id:\n","        break\n","\n","  # Decode tokens back into text\n","  generated_text = tokenizer.decode(generated_ids.squeeze().tolist())\n","  return generated_text\n"]},{"cell_type":"code","execution_count":4,"id":"490dea4e","metadata":{"execution":{"iopub.execute_input":"2025-02-11T12:51:12.984856Z","iopub.status.busy":"2025-02-11T12:51:12.984629Z","iopub.status.idle":"2025-02-11T12:51:12.988845Z","shell.execute_reply":"2025-02-11T12:51:12.988085Z"},"papermill":{"duration":0.008605,"end_time":"2025-02-11T12:51:12.990181","exception":false,"start_time":"2025-02-11T12:51:12.981576","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Memory allocated: 0.0 GB\n","Memory reserved: 0.0 GB\n"]}],"source":["torch.cuda.empty_cache()\n","print(f\"Memory allocated: {torch.cuda.memory_allocated() / 1e9} GB\")\n","print(f\"Memory reserved: {torch.cuda.memory_reserved() / 1e9} GB\")"]},{"cell_type":"code","execution_count":5,"id":"28e4aca3","metadata":{"execution":{"iopub.execute_input":"2025-02-11T12:51:12.995965Z","iopub.status.busy":"2025-02-11T12:51:12.995743Z","iopub.status.idle":"2025-02-11T12:51:22.444969Z","shell.execute_reply":"2025-02-11T12:51:22.444301Z"},"papermill":{"duration":9.453766,"end_time":"2025-02-11T12:51:22.446525","exception":false,"start_time":"2025-02-11T12:51:12.992759","status":"completed"},"tags":[]},"outputs":[],"source":["class DataLoaderLite:\n","  def __init__(self, B,T):\n","    self.B=B\n","    self.T=T\n","    with open('../input/llm-data-set-of-julius-caesar/input.txt', 'r') as f:\n","      text = f.read()\n","    enc = tiktoken.get_encoding('gpt2')\n","    tokens = enc.encode(text)\n","    self.tokens = torch.tensor(tokens)\n","\n","    self.current_position = 0\n","\n","  def next_batch(self):\n","    B, T = self.B, self.T\n","    buf = self.tokens[self.current_position:self.current_position + B*T+1]\n","    x = (buf[:-1]).view(B,T)\n","    y = (buf[1:]).view(B,T)\n","\n","    self.current_position+=B*T\n","    if(self.current_position+(B*T+1)>len(self.tokens)):\n","      self.current_position=0\n","    return x, y\n","\n","train_loader = DataLoaderLite(B=4,T=32)\n","model = GPT(GPTConfig(vocab_size=50304))\n","model.to(device)\n","model.eval()\n","model=torch.compile(model)"]},{"cell_type":"code","execution_count":6,"id":"e58a191b","metadata":{"execution":{"iopub.execute_input":"2025-02-11T12:51:22.453055Z","iopub.status.busy":"2025-02-11T12:51:22.452703Z","iopub.status.idle":"2025-02-11T12:52:11.650581Z","shell.execute_reply":"2025-02-11T12:52:11.649643Z"},"papermill":{"duration":49.202756,"end_time":"2025-02-11T12:52:11.652186","exception":false,"start_time":"2025-02-11T12:51:22.44943","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125] WON'T CONVERT forward <ipython-input-3-3260b12a3d48> line 39 \n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125] due to: \n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125] Traceback (most recent call last):\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py\", line 1446, in _call_user_compiler\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py\", line 129, in __call__\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/__init__.py\", line 2234, in __call__\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py\", line 1521, in compile_fx\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     return aot_autograd(\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py\", line 72, in __call__\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py\", line 1071, in aot_module_simplified\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py\", line 1056, in dispatch_and_compile\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py\", line 522, in create_aot_dispatcher_function\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     return _create_aot_dispatcher_function(\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py\", line 588, in aot_dispatch_autograd\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py\", line 1350, in fw_compiler_base\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py\", line 1421, in _fw_compiler_base\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     return inner_compile(\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py\", line 475, in compile_fx_inner\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py\", line 85, in debug_wrapper\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py\", line 661, in _compile_fx_inner\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py\", line 1334, in load\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py\", line 570, in codegen_and_compile\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py\", line 878, in fx_codegen_and_compile\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py\", line 1913, in compile_to_fn\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     return self.compile_to_module().call\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py\", line 1839, in compile_to_module\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     return self._compile_to_module()\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py\", line 1845, in _compile_to_module\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py\", line 1780, in codegen\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/scheduler.py\", line 1731, in __init__\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     self._init(nodes)\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/scheduler.py\", line 1749, in _init\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/scheduler.py\", line 1749, in <listcomp>\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/scheduler.py\", line 1856, in create_scheduler_node\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     return SchedulerNode(self, node)\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/scheduler.py\", line 833, in __init__\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     self._compute_attrs()\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/scheduler.py\", line 846, in _compute_attrs\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/scheduler.py\", line 3360, in get_backend\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/scheduler.py\", line 3352, in create_backend\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     raise RuntimeError(\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125] \n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125] The above exception was the direct cause of the following exception:\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125] \n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125] Traceback (most recent call last):\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\", line 1064, in __call__\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     result = self._inner_convert(\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\", line 526, in __call__\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     return _compile(\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\", line 924, in _compile\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\", line 666, in compile_inner\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_utils_internal.py\", line 87, in wrapper_function\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     return function(*args, **kwargs)\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\", line 699, in _compile_inner\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py\", line 1322, in transform_code_object\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     transformations(instructions, code_options)\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\", line 219, in _fn\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     return fn(*args, **kwargs)\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\", line 634, in transform\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     tracer.run()\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py\", line 2796, in run\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     super().run()\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py\", line 983, in run\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     while self.step():\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py\", line 895, in step\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py\", line 2987, in RETURN_VALUE\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     self._return(inst)\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py\", line 2972, in _return\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     self.output.compile_subgraph(\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py\", line 1142, in compile_subgraph\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, pass2.graph_output_vars(), root)\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py\", line 1369, in compile_and_call_fx_graph\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py\", line 1416, in call_user_compiler\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     return self._call_user_compiler(gm)\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py\", line 1465, in _call_user_compiler\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125] \n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125] \n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125] Traceback (most recent call last):\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py\", line 1446, in _call_user_compiler\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py\", line 129, in __call__\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/__init__.py\", line 2234, in __call__\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py\", line 1521, in compile_fx\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     return aot_autograd(\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py\", line 72, in __call__\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py\", line 1071, in aot_module_simplified\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py\", line 1056, in dispatch_and_compile\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py\", line 522, in create_aot_dispatcher_function\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     return _create_aot_dispatcher_function(\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py\", line 588, in aot_dispatch_autograd\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py\", line 1350, in fw_compiler_base\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py\", line 1421, in _fw_compiler_base\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     return inner_compile(\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py\", line 475, in compile_fx_inner\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py\", line 85, in debug_wrapper\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py\", line 661, in _compile_fx_inner\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py\", line 1334, in load\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py\", line 570, in codegen_and_compile\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py\", line 878, in fx_codegen_and_compile\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py\", line 1913, in compile_to_fn\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     return self.compile_to_module().call\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py\", line 1839, in compile_to_module\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     return self._compile_to_module()\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py\", line 1845, in _compile_to_module\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py\", line 1780, in codegen\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/scheduler.py\", line 1731, in __init__\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     self._init(nodes)\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/scheduler.py\", line 1749, in _init\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/scheduler.py\", line 1749, in <listcomp>\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/scheduler.py\", line 1856, in create_scheduler_node\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     return SchedulerNode(self, node)\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/scheduler.py\", line 833, in __init__\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     self._compute_attrs()\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/scheduler.py\", line 846, in _compute_attrs\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/scheduler.py\", line 3360, in get_backend\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/scheduler.py\", line 3352, in create_backend\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     raise RuntimeError(\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125] \n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125] The above exception was the direct cause of the following exception:\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125] \n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125] Traceback (most recent call last):\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\", line 1064, in __call__\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     result = self._inner_convert(\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\", line 526, in __call__\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     return _compile(\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\", line 924, in _compile\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\", line 666, in compile_inner\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_utils_internal.py\", line 87, in wrapper_function\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     return function(*args, **kwargs)\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\", line 699, in _compile_inner\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py\", line 1322, in transform_code_object\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     transformations(instructions, code_options)\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\", line 219, in _fn\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     return fn(*args, **kwargs)\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\", line 634, in transform\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     tracer.run()\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py\", line 2796, in run\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     super().run()\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py\", line 983, in run\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     while self.step():\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py\", line 895, in step\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py\", line 2987, in RETURN_VALUE\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     self._return(inst)\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py\", line 2972, in _return\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     self.output.compile_subgraph(\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py\", line 1142, in compile_subgraph\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, pass2.graph_output_vars(), root)\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py\", line 1369, in compile_and_call_fx_graph\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py\", line 1416, in call_user_compiler\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     return self._call_user_compiler(gm)\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py\", line 1465, in _call_user_compiler\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125] \n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n","W0211 12:51:31.853000 18 torch/_dynamo/convert_frame.py:1125] \n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125] WON'T CONVERT forward <ipython-input-2-de549c493e05> line 55 \n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125] due to: \n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125] Traceback (most recent call last):\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py\", line 1446, in _call_user_compiler\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py\", line 129, in __call__\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/__init__.py\", line 2234, in __call__\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py\", line 1521, in compile_fx\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     return aot_autograd(\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py\", line 72, in __call__\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py\", line 1071, in aot_module_simplified\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py\", line 1056, in dispatch_and_compile\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py\", line 522, in create_aot_dispatcher_function\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     return _create_aot_dispatcher_function(\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py\", line 588, in aot_dispatch_autograd\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py\", line 1350, in fw_compiler_base\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py\", line 1421, in _fw_compiler_base\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     return inner_compile(\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py\", line 475, in compile_fx_inner\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py\", line 85, in debug_wrapper\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py\", line 661, in _compile_fx_inner\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py\", line 1334, in load\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py\", line 570, in codegen_and_compile\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py\", line 878, in fx_codegen_and_compile\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py\", line 1913, in compile_to_fn\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     return self.compile_to_module().call\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py\", line 1839, in compile_to_module\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     return self._compile_to_module()\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py\", line 1845, in _compile_to_module\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py\", line 1780, in codegen\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/scheduler.py\", line 1731, in __init__\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     self._init(nodes)\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/scheduler.py\", line 1749, in _init\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/scheduler.py\", line 1749, in <listcomp>\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/scheduler.py\", line 1856, in create_scheduler_node\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     return SchedulerNode(self, node)\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/scheduler.py\", line 833, in __init__\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     self._compute_attrs()\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/scheduler.py\", line 846, in _compute_attrs\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/scheduler.py\", line 3360, in get_backend\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/scheduler.py\", line 3352, in create_backend\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     raise RuntimeError(\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125] \n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125] The above exception was the direct cause of the following exception:\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125] \n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125] Traceback (most recent call last):\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\", line 1064, in __call__\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     result = self._inner_convert(\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\", line 526, in __call__\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     return _compile(\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\", line 924, in _compile\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\", line 666, in compile_inner\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_utils_internal.py\", line 87, in wrapper_function\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     return function(*args, **kwargs)\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\", line 699, in _compile_inner\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py\", line 1322, in transform_code_object\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     transformations(instructions, code_options)\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\", line 219, in _fn\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     return fn(*args, **kwargs)\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\", line 634, in transform\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     tracer.run()\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py\", line 2796, in run\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     super().run()\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py\", line 983, in run\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     while self.step():\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py\", line 895, in step\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py\", line 2987, in RETURN_VALUE\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     self._return(inst)\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py\", line 2972, in _return\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     self.output.compile_subgraph(\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py\", line 1117, in compile_subgraph\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py\", line 1369, in compile_and_call_fx_graph\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py\", line 1416, in call_user_compiler\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     return self._call_user_compiler(gm)\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py\", line 1465, in _call_user_compiler\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125] \n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125] \n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125] Traceback (most recent call last):\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py\", line 1446, in _call_user_compiler\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py\", line 129, in __call__\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/__init__.py\", line 2234, in __call__\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py\", line 1521, in compile_fx\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     return aot_autograd(\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py\", line 72, in __call__\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py\", line 1071, in aot_module_simplified\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py\", line 1056, in dispatch_and_compile\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py\", line 522, in create_aot_dispatcher_function\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     return _create_aot_dispatcher_function(\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py\", line 588, in aot_dispatch_autograd\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py\", line 1350, in fw_compiler_base\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py\", line 1421, in _fw_compiler_base\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     return inner_compile(\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py\", line 475, in compile_fx_inner\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py\", line 85, in debug_wrapper\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py\", line 661, in _compile_fx_inner\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py\", line 1334, in load\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py\", line 570, in codegen_and_compile\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py\", line 878, in fx_codegen_and_compile\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py\", line 1913, in compile_to_fn\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     return self.compile_to_module().call\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py\", line 1839, in compile_to_module\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     return self._compile_to_module()\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py\", line 1845, in _compile_to_module\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py\", line 1780, in codegen\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/scheduler.py\", line 1731, in __init__\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     self._init(nodes)\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/scheduler.py\", line 1749, in _init\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/scheduler.py\", line 1749, in <listcomp>\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/scheduler.py\", line 1856, in create_scheduler_node\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     return SchedulerNode(self, node)\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/scheduler.py\", line 833, in __init__\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     self._compute_attrs()\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/scheduler.py\", line 846, in _compute_attrs\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/scheduler.py\", line 3360, in get_backend\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/scheduler.py\", line 3352, in create_backend\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     raise RuntimeError(\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125] \n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125] The above exception was the direct cause of the following exception:\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125] \n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125] Traceback (most recent call last):\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\", line 1064, in __call__\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     result = self._inner_convert(\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\", line 526, in __call__\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     return _compile(\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\", line 924, in _compile\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\", line 666, in compile_inner\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_utils_internal.py\", line 87, in wrapper_function\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     return function(*args, **kwargs)\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\", line 699, in _compile_inner\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py\", line 1322, in transform_code_object\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     transformations(instructions, code_options)\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\", line 219, in _fn\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     return fn(*args, **kwargs)\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\", line 634, in transform\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     tracer.run()\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py\", line 2796, in run\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     super().run()\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py\", line 983, in run\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     while self.step():\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py\", line 895, in step\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py\", line 2987, in RETURN_VALUE\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     self._return(inst)\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py\", line 2972, in _return\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     self.output.compile_subgraph(\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py\", line 1117, in compile_subgraph\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py\", line 1369, in compile_and_call_fx_graph\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py\", line 1416, in call_user_compiler\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     return self._call_user_compiler(gm)\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py\", line 1465, in _call_user_compiler\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125] \n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n","W0211 12:51:32.549000 18 torch/_dynamo/convert_frame.py:1125] \n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125] WON'T CONVERT forward <ipython-input-2-de549c493e05> line 15 \n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125] due to: \n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125] Traceback (most recent call last):\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py\", line 1446, in _call_user_compiler\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py\", line 129, in __call__\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/__init__.py\", line 2234, in __call__\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py\", line 1521, in compile_fx\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     return aot_autograd(\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py\", line 72, in __call__\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py\", line 1071, in aot_module_simplified\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py\", line 1056, in dispatch_and_compile\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py\", line 522, in create_aot_dispatcher_function\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     return _create_aot_dispatcher_function(\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py\", line 588, in aot_dispatch_autograd\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py\", line 1350, in fw_compiler_base\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py\", line 1421, in _fw_compiler_base\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     return inner_compile(\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py\", line 475, in compile_fx_inner\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py\", line 85, in debug_wrapper\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py\", line 661, in _compile_fx_inner\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py\", line 1334, in load\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py\", line 570, in codegen_and_compile\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py\", line 878, in fx_codegen_and_compile\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py\", line 1913, in compile_to_fn\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     return self.compile_to_module().call\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py\", line 1839, in compile_to_module\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     return self._compile_to_module()\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py\", line 1845, in _compile_to_module\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py\", line 1784, in codegen\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     self.scheduler.codegen()\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/scheduler.py\", line 3383, in codegen\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     return self._codegen()\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/scheduler.py\", line 3474, in _codegen\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     if device is not None and self.get_backend(device).ready_to_flush():\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/scheduler.py\", line 3360, in get_backend\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/scheduler.py\", line 3352, in create_backend\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     raise RuntimeError(\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125] \n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125] The above exception was the direct cause of the following exception:\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125] \n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125] Traceback (most recent call last):\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\", line 1064, in __call__\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     result = self._inner_convert(\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\", line 526, in __call__\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     return _compile(\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\", line 924, in _compile\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\", line 666, in compile_inner\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_utils_internal.py\", line 87, in wrapper_function\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     return function(*args, **kwargs)\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\", line 699, in _compile_inner\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py\", line 1322, in transform_code_object\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     transformations(instructions, code_options)\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\", line 219, in _fn\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     return fn(*args, **kwargs)\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\", line 634, in transform\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     tracer.run()\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py\", line 2796, in run\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     super().run()\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py\", line 983, in run\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     while self.step():\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py\", line 895, in step\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py\", line 2987, in RETURN_VALUE\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     self._return(inst)\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py\", line 2972, in _return\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     self.output.compile_subgraph(\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py\", line 1117, in compile_subgraph\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py\", line 1369, in compile_and_call_fx_graph\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py\", line 1416, in call_user_compiler\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     return self._call_user_compiler(gm)\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py\", line 1465, in _call_user_compiler\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125] \n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125] \n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125] Traceback (most recent call last):\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py\", line 1446, in _call_user_compiler\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py\", line 129, in __call__\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/__init__.py\", line 2234, in __call__\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py\", line 1521, in compile_fx\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     return aot_autograd(\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py\", line 72, in __call__\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py\", line 1071, in aot_module_simplified\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py\", line 1056, in dispatch_and_compile\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py\", line 522, in create_aot_dispatcher_function\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     return _create_aot_dispatcher_function(\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py\", line 588, in aot_dispatch_autograd\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py\", line 1350, in fw_compiler_base\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py\", line 1421, in _fw_compiler_base\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     return inner_compile(\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py\", line 475, in compile_fx_inner\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py\", line 85, in debug_wrapper\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py\", line 661, in _compile_fx_inner\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py\", line 1334, in load\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py\", line 570, in codegen_and_compile\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py\", line 878, in fx_codegen_and_compile\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py\", line 1913, in compile_to_fn\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     return self.compile_to_module().call\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py\", line 1839, in compile_to_module\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     return self._compile_to_module()\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py\", line 1845, in _compile_to_module\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py\", line 1784, in codegen\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     self.scheduler.codegen()\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/scheduler.py\", line 3383, in codegen\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     return self._codegen()\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/scheduler.py\", line 3474, in _codegen\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     if device is not None and self.get_backend(device).ready_to_flush():\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/scheduler.py\", line 3360, in get_backend\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/scheduler.py\", line 3352, in create_backend\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     raise RuntimeError(\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125] \n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125] The above exception was the direct cause of the following exception:\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125] \n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125] Traceback (most recent call last):\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\", line 1064, in __call__\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     result = self._inner_convert(\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\", line 526, in __call__\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     return _compile(\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\", line 924, in _compile\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\", line 666, in compile_inner\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_utils_internal.py\", line 87, in wrapper_function\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     return function(*args, **kwargs)\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\", line 699, in _compile_inner\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py\", line 1322, in transform_code_object\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     transformations(instructions, code_options)\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\", line 219, in _fn\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     return fn(*args, **kwargs)\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\", line 634, in transform\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     tracer.run()\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py\", line 2796, in run\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     super().run()\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py\", line 983, in run\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     while self.step():\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py\", line 895, in step\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py\", line 2987, in RETURN_VALUE\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     self._return(inst)\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py\", line 2972, in _return\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     self.output.compile_subgraph(\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py\", line 1117, in compile_subgraph\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py\", line 1369, in compile_and_call_fx_graph\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py\", line 1416, in call_user_compiler\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     return self._call_user_compiler(gm)\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py\", line 1465, in _call_user_compiler\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125] \n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n","W0211 12:51:32.833000 18 torch/_dynamo/convert_frame.py:1125] \n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125] WON'T CONVERT forward <ipython-input-2-de549c493e05> line 40 \n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125] due to: \n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125] Traceback (most recent call last):\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py\", line 1446, in _call_user_compiler\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py\", line 129, in __call__\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/__init__.py\", line 2234, in __call__\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py\", line 1521, in compile_fx\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     return aot_autograd(\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py\", line 72, in __call__\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py\", line 1071, in aot_module_simplified\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py\", line 1056, in dispatch_and_compile\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py\", line 522, in create_aot_dispatcher_function\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     return _create_aot_dispatcher_function(\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py\", line 588, in aot_dispatch_autograd\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py\", line 1350, in fw_compiler_base\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py\", line 1421, in _fw_compiler_base\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     return inner_compile(\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py\", line 475, in compile_fx_inner\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py\", line 85, in debug_wrapper\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py\", line 661, in _compile_fx_inner\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py\", line 1334, in load\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py\", line 570, in codegen_and_compile\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py\", line 878, in fx_codegen_and_compile\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py\", line 1913, in compile_to_fn\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     return self.compile_to_module().call\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py\", line 1839, in compile_to_module\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     return self._compile_to_module()\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py\", line 1845, in _compile_to_module\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py\", line 1780, in codegen\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/scheduler.py\", line 1731, in __init__\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     self._init(nodes)\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/scheduler.py\", line 1749, in _init\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/scheduler.py\", line 1749, in <listcomp>\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/scheduler.py\", line 1856, in create_scheduler_node\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     return SchedulerNode(self, node)\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/scheduler.py\", line 833, in __init__\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     self._compute_attrs()\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/scheduler.py\", line 846, in _compute_attrs\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/scheduler.py\", line 3360, in get_backend\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/scheduler.py\", line 3352, in create_backend\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     raise RuntimeError(\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125] \n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125] The above exception was the direct cause of the following exception:\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125] \n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125] Traceback (most recent call last):\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\", line 1064, in __call__\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     result = self._inner_convert(\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\", line 526, in __call__\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     return _compile(\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\", line 924, in _compile\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\", line 666, in compile_inner\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_utils_internal.py\", line 87, in wrapper_function\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     return function(*args, **kwargs)\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\", line 699, in _compile_inner\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py\", line 1322, in transform_code_object\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     transformations(instructions, code_options)\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\", line 219, in _fn\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     return fn(*args, **kwargs)\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\", line 634, in transform\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     tracer.run()\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py\", line 2796, in run\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     super().run()\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py\", line 983, in run\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     while self.step():\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py\", line 895, in step\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py\", line 2987, in RETURN_VALUE\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     self._return(inst)\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py\", line 2972, in _return\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     self.output.compile_subgraph(\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py\", line 1117, in compile_subgraph\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py\", line 1369, in compile_and_call_fx_graph\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py\", line 1416, in call_user_compiler\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     return self._call_user_compiler(gm)\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py\", line 1465, in _call_user_compiler\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125] \n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125] \n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125] Traceback (most recent call last):\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py\", line 1446, in _call_user_compiler\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py\", line 129, in __call__\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/__init__.py\", line 2234, in __call__\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py\", line 1521, in compile_fx\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     return aot_autograd(\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py\", line 72, in __call__\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py\", line 1071, in aot_module_simplified\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py\", line 1056, in dispatch_and_compile\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py\", line 522, in create_aot_dispatcher_function\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     return _create_aot_dispatcher_function(\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py\", line 588, in aot_dispatch_autograd\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py\", line 1350, in fw_compiler_base\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py\", line 1421, in _fw_compiler_base\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     return inner_compile(\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py\", line 475, in compile_fx_inner\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py\", line 85, in debug_wrapper\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py\", line 661, in _compile_fx_inner\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/codecache.py\", line 1334, in load\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py\", line 570, in codegen_and_compile\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py\", line 878, in fx_codegen_and_compile\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py\", line 1913, in compile_to_fn\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     return self.compile_to_module().call\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py\", line 1839, in compile_to_module\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     return self._compile_to_module()\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py\", line 1845, in _compile_to_module\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py\", line 1780, in codegen\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/scheduler.py\", line 1731, in __init__\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     self._init(nodes)\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/scheduler.py\", line 1749, in _init\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/scheduler.py\", line 1749, in <listcomp>\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/scheduler.py\", line 1856, in create_scheduler_node\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     return SchedulerNode(self, node)\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/scheduler.py\", line 833, in __init__\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     self._compute_attrs()\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/scheduler.py\", line 846, in _compute_attrs\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/scheduler.py\", line 3360, in get_backend\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/scheduler.py\", line 3352, in create_backend\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     raise RuntimeError(\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125] \n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125] The above exception was the direct cause of the following exception:\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125] \n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125] Traceback (most recent call last):\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\", line 1064, in __call__\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     result = self._inner_convert(\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\", line 526, in __call__\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     return _compile(\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\", line 924, in _compile\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\", line 666, in compile_inner\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_utils_internal.py\", line 87, in wrapper_function\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     return function(*args, **kwargs)\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\", line 699, in _compile_inner\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py\", line 1322, in transform_code_object\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     transformations(instructions, code_options)\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\", line 219, in _fn\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     return fn(*args, **kwargs)\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\", line 634, in transform\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     tracer.run()\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py\", line 2796, in run\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     super().run()\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py\", line 983, in run\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     while self.step():\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py\", line 895, in step\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py\", line 2987, in RETURN_VALUE\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     self._return(inst)\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py\", line 2972, in _return\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     self.output.compile_subgraph(\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py\", line 1117, in compile_subgraph\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py\", line 1369, in compile_and_call_fx_graph\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py\", line 1416, in call_user_compiler\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     return self._call_user_compiler(gm)\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]   File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py\", line 1465, in _call_user_compiler\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125] \n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n","W0211 12:51:33.128000 18 torch/_dynamo/convert_frame.py:1125] \n"]},{"name":"stdout","output_type":"stream","text":["step 0.0, loss: 11.019079208374023\n","step 1.0, loss: 5.262796878814697\n","step 2.0, loss: 5.709054946899414\n"]}],"source":["import torch._dynamo\n","torch._dynamo.config.suppress_errors = True\n","max_lr = 3e-4\n","min_lr = max_lr*0.1\n","warmup_steps=100\n","max_steps = 500\n","def get_lr(it):\n","  if it<=warmup_steps:\n","    return max_lr*(it+1)/warmup_steps\n","  if it>=max_steps:\n","    return min_lr\n","\n","  decay_ratio = (it-warmup_steps)/(max_steps-warmup_steps)\n","  assert 0<=decay_ratio<=1\n","  coeff=0.5*(1.0+math.cos(math.pi*decay_ratio))\n","  return min_lr + coeff*(max_lr-min_lr)\n","\n","\n","\n","# try B = 16, T=1024 once\n","optimizer = torch.optim.AdamW(model.parameters(),lr=3e-4, betas = (0.9,0.95), eps=1e-8)\n","try:\n","    for step in range(max_steps):\n","        x, y = train_loader.next_batch()\n","        x, y = x.to(device), y.to(device)\n","\n","        optimizer.zero_grad()\n","        logits, loss = model(x, y)\n","        loss.backward()\n","        norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        lr = get_lr(step)\n","        for param_group in optimizer.param_groups:\n","            param_group['lr'] = lr\n","\n","        optimizer.step()\n","        if step%200==0:\n","            print(f\"step {step/200}, loss: {loss.item()}\")\n","except Exception as e:\n","    print(f\"Training failed with error: {e}\")"]},{"cell_type":"code","execution_count":7,"id":"f4c103af","metadata":{"execution":{"iopub.execute_input":"2025-02-11T12:52:11.66254Z","iopub.status.busy":"2025-02-11T12:52:11.66211Z","iopub.status.idle":"2025-02-11T12:52:11.710421Z","shell.execute_reply":"2025-02-11T12:52:11.70976Z"},"papermill":{"duration":0.054882,"end_time":"2025-02-11T12:52:11.711695","exception":false,"start_time":"2025-02-11T12:52:11.656813","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["final loss=\n"]},{"data":{"text/plain":["6.1564741134643555"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["print(\"final loss=\")\n","loss.item()"]},{"cell_type":"code","execution_count":8,"id":"b2809cd6","metadata":{"execution":{"iopub.execute_input":"2025-02-11T12:52:11.721162Z","iopub.status.busy":"2025-02-11T12:52:11.720908Z","iopub.status.idle":"2025-02-11T12:52:12.526852Z","shell.execute_reply":"2025-02-11T12:52:12.525843Z"},"papermill":{"duration":0.812337,"end_time":"2025-02-11T12:52:12.528338","exception":false,"start_time":"2025-02-11T12:52:11.716001","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Model saved successfully at /kaggle/working/trained_gpt_model.pth\n"]}],"source":["save_path = \"/kaggle/working/trained_gpt_model.pth\"\n","# Save the uncompiled model's state dictionary\n","torch.save(model.state_dict(), save_path)\n","print(f\"Model saved successfully at {save_path}\")"]},{"cell_type":"code","execution_count":9,"id":"77536934","metadata":{"execution":{"iopub.execute_input":"2025-02-11T12:52:12.538362Z","iopub.status.busy":"2025-02-11T12:52:12.538106Z","iopub.status.idle":"2025-02-11T12:52:15.626061Z","shell.execute_reply":"2025-02-11T12:52:15.625115Z"},"papermill":{"duration":3.094366,"end_time":"2025-02-11T12:52:15.627474","exception":false,"start_time":"2025-02-11T12:52:12.533108","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-9-1ed0c49de78f>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  state_dict = torch.load(\"trained_gpt_model.pth\", map_location=device)\n"]},{"name":"stdout","output_type":"stream","text":["Model loaded successfully.\n"]}],"source":["# Load the state dictionary\n","state_dict = torch.load(\"trained_gpt_model.pth\", map_location=device)\n","\n","# Remove \"_orig_mod.\" prefix from keys\n","adjusted_state_dict = {k.replace(\"_orig_mod.\", \"\"): v for k, v in state_dict.items()}\n","\n","# Load the adjusted state dictionary into a fresh model\n","model = GPT(GPTConfig(vocab_size=50304))  # Reinitialize the model\n","model.load_state_dict(adjusted_state_dict)\n","model.to(device)\n","model.eval()\n","print(\"Model loaded successfully.\")"]},{"cell_type":"code","execution_count":10,"id":"22706260","metadata":{"execution":{"iopub.execute_input":"2025-02-11T12:52:15.637727Z","iopub.status.busy":"2025-02-11T12:52:15.637469Z","iopub.status.idle":"2025-02-11T12:52:15.955312Z","shell.execute_reply":"2025-02-11T12:52:15.954306Z"},"papermill":{"duration":0.324272,"end_time":"2025-02-11T12:52:15.956715","exception":false,"start_time":"2025-02-11T12:52:15.632443","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Generated Text:\n","I am an LLM.. doing:\n"," everIPP-ES Mly may itians,\n","The then: me!'t\n"]}],"source":["input_text = \"I am an LLM..\"\n","\n","# Generate text\n","output = generate_text(model, input_text, max_tokens=20, device=device)\n","print(\"Generated Text:\")\n","print(output)"]},{"cell_type":"code","execution_count":null,"id":"6b1bb656","metadata":{"papermill":{"duration":0.004482,"end_time":"2025-02-11T12:52:15.96653","exception":false,"start_time":"2025-02-11T12:52:15.962048","status":"completed"},"tags":[]},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4505706,"sourceId":7715091,"sourceType":"datasetVersion"}],"dockerImageVersionId":30840,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":71.474257,"end_time":"2025-02-11T12:52:17.893674","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-02-11T12:51:06.419417","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}